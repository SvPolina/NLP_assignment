{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_engineer_test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN40u7RZeR7KUkxBCb/CQrh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDVlBsLJY3lJ","executionInfo":{"status":"ok","timestamp":1626946331252,"user_tz":-180,"elapsed":1157,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"d06400ea-a37b-4dbd-d1ee-79fda7664043"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kb9IvuvAcgIM"},"source":["I've chosen the third assignment , to classify \n","if a given bigram is a collocation or rather a co-oocurance.\n","\n","Let's start with some motivation why extraction of collocations might be of interest.\n","1. Improving insight analysis and topic modeling.\n","2. Most relevant key word identification in document."]},{"cell_type":"code","metadata":{"id":"zq9GvNqPgna2"},"source":["import os\n","PATH='/content/gdrive/MyDrive/gdrive/Github'\n","os.chdir(os.path.join(PATH,'NLP_assignment'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8OOykWTfkOv"},"source":["The data sets we will use\n","\n","Hotel reviews data:\n","https://www.kaggle.com/datafiniti/hotel-reviews/data\n","\n","The relevant data set is in 7282_1.csv file with the relevant reviews column : reviews.text\n","\n","This dataset was chosen mainly because it is small (to save processing time),\n","but still descriptive enough to demonstrate the approach.\n","\n","The first step is as always the data preparation . All the required functions are at the clean_data.py script.\n","\n","Functions as puctuation removal, non_ascii_chars removal contraction_expantion , etc. are present at this script.\n","The function prepare_data , applies in logical order all the functions above to the reviews so eventually we can get a text appropriate to work with. "]},{"cell_type":"code","metadata":{"id":"Rdwld0yjkmwK"},"source":["!pip install contractions\n","!python -m spacy download en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c6s9Uas84L1"},"source":["import clean_data\n","from clean_data import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Hi0nAmVo9wN"},"source":["#load data\n","reviews = pd.read_csv('7282_1.csv')\n","#extract reviews\n","comments = reviews[['reviews.text']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXnb4D_esu7g"},"source":["comments_preproccesed=clean_data.prepare_data(comments,'reviews.text')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"oOcHEa94JDpz","executionInfo":{"status":"ok","timestamp":1626946490334,"user_tz":-180,"elapsed":34,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"78210b55-c352-481f-82be-28505375e721"},"source":["comments_preproccesed.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviews.text</th>\n","      <th>processed_reviews.text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Pleasant 10 min walk along the sea front to th...</td>\n","      <td>[pleasant, 10, min, walk, along, the, sea, fro...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Really lovely hotel. Stayed on the very top fl...</td>\n","      <td>[really, lovely, hotel, stay, on, the, very, t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We stayed here for four nights in October. The...</td>\n","      <td>[we, stay, here, for, four, night, in, october...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>We loved staying on the island of Lido! You ne...</td>\n","      <td>[we, love, stay, on, the, island, of, lido, yo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Lovely view out onto the lagoon. Excellent vie...</td>\n","      <td>[lovely, view, out, onto, the, lagoon, excelle...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        reviews.text                             processed_reviews.text\n","0  Pleasant 10 min walk along the sea front to th...  [pleasant, 10, min, walk, along, the, sea, fro...\n","1  Really lovely hotel. Stayed on the very top fl...  [really, lovely, hotel, stay, on, the, very, t...\n","2  We stayed here for four nights in October. The...  [we, stay, here, for, four, night, in, october...\n","3  We loved staying on the island of Lido! You ne...  [we, love, stay, on, the, island, of, lido, yo...\n","4  Lovely view out onto the lagoon. Excellent vie...  [lovely, view, out, onto, the, lagoon, excelle..."]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"-DkASoot1nUD"},"source":["comments_list=comments_preproccesed[\"processed_reviews.text\"].values\n","final=[val for sublist in comments_list for val in sublist]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vit7kf1UGkMl"},"source":["Lets generate some bigrams and rank them by frequency"]},{"cell_type":"code","metadata":{"id":"sj6ZO7s1BLdg"},"source":["bigrams = nltk.collocations.BigramAssocMeasures()\n","bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(final)\n","bigram_freq = bigramFinder.ngram_fd.items()\n","bigramFreq = pd.DataFrame(list(bigram_freq), columns=['bigram','freq']).sort_values(by='freq', ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R5WqbtuKGoTu"},"source":["Let's take a look at the bigrams"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"K-l4p1QqBuOt","executionInfo":{"status":"ok","timestamp":1626946495401,"user_tz":-180,"elapsed":20,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"1afbae8c-a7de-49c6-da33-c80e1ff3dad3"},"source":["bigramFreq[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>193</th>\n","      <td>(it, be)</td>\n","      <td>8995</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>(the, room)</td>\n","      <td>8782</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>(room, be)</td>\n","      <td>8431</td>\n","    </tr>\n","    <tr>\n","      <th>302</th>\n","      <td>(in, the)</td>\n","      <td>8240</td>\n","    </tr>\n","    <tr>\n","      <th>171</th>\n","      <td>(be, very)</td>\n","      <td>7733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          bigram  freq\n","193     (it, be)  8995\n","96   (the, room)  8782\n","97    (room, be)  8431\n","302    (in, the)  8240\n","171   (be, very)  7733"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"AFZwVpn1GrGi"},"source":["We see that the stop words, articles, prepositions or pronouns  present at the texts are common , not meaningfull and prevent us from obtaining a meaningfull\n","co-occurance/collocations list.\n","\n","Let's to something about it!\n","\n","We will filter out those bigrams that not contain the above mentioned,\n","and are of the following structure:\n","\n","(Noun, Noun), (Adjective, Noun)\n","\n","Practically, we will apply a POS filter.\n","\n","The function filter_matching is present at the clean_data file"]},{"cell_type":"code","metadata":{"id":"XcA6SA2wOfHc"},"source":["filtered_bigrams = bigramFreq[bigramFreq.bigram.map(lambda x: clean_data.filter_matching(x))]  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"WefITPF-ppq3","executionInfo":{"status":"ok","timestamp":1626946529368,"user_tz":-180,"elapsed":20,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"5e049f97-38a2-44da-f449-d6b89a16f1ac"},"source":["filtered_bigrams.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1033</th>\n","      <td>(front, desk)</td>\n","      <td>2616</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>(great, location)</td>\n","      <td>795</td>\n","    </tr>\n","    <tr>\n","      <th>252</th>\n","      <td>(friendly, staff)</td>\n","      <td>761</td>\n","    </tr>\n","    <tr>\n","      <th>2450</th>\n","      <td>(walk, distance)</td>\n","      <td>684</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>(clean, room)</td>\n","      <td>639</td>\n","    </tr>\n","    <tr>\n","      <th>5190</th>\n","      <td>(hot, tub)</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>(hotel, staff)</td>\n","      <td>590</td>\n","    </tr>\n","    <tr>\n","      <th>249</th>\n","      <td>(nice, hotel)</td>\n","      <td>528</td>\n","    </tr>\n","    <tr>\n","      <th>3006</th>\n","      <td>(continental, breakfast)</td>\n","      <td>521</td>\n","    </tr>\n","    <tr>\n","      <th>4042</th>\n","      <td>(free, breakfast)</td>\n","      <td>520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        bigram  freq\n","1033             (front, desk)  2616\n","65           (great, location)   795\n","252          (friendly, staff)   761\n","2450          (walk, distance)   684\n","1435             (clean, room)   639\n","5190                (hot, tub)   593\n","85              (hotel, staff)   590\n","249              (nice, hotel)   528\n","3006  (continental, breakfast)   521\n","4042         (free, breakfast)   520"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"U4pth7GVP4lR"},"source":["Looks much better now!\n","\n","We see that the top resutls filtered by POS filter and ranked by frequency are in fact mixture , \n","between words that actually make more sense together and more commonly co-occur in a given context than in separate, they are collocations - such as walk-distance , or front-desk,\n","and bigrams that are just co-occurancies, such as nice hotel. \n","We see that we can't rely only on the frequency measure to identify to which group the given bigram belongs to.\n","So...\n","Let's try more sophisticated analysis!\n","\n","Let's make hypothesis testing with 3 tests :\n","t-test , chi-square , Likelihood ratios\n","\n","**T-test** : \n","\n","Is used to compare the mean of two given samples. \n","\n","Point to notice!: \n","The t-test assumes that probabilities are approximately\n","normally distributed, which is not true in general!!!\n","\n","Let's assume our corpus is of N words , and we examine some given bigram (a1, a2) .\n","Null hypothesis : a1 and a2 are independent:\n","\n","Ho= \"a1 a2\" occurance has probability : $\\mu=P(a1)P(a2)=Count(a1)/N * Count(a2)/N$\n","\n","Alternative hypothesis:\n","\n","H1 : \"a1 a2\" occurance does not have expected probability $\\mu$\n","\n","t-statistic score :      $t=(Count(a1 a2)/N - \\mu)/\\sqrt(s^2/N)$\n","\n","for Bernoulli trial :      $s^2=P(1-P)\\approx$P$\\approx$Count(a1 a2)/N  \n","\n","\n","**Chi-square test** :\n","\n","Point to notice!: \n","1. The chi-square test does not assume normally distributed probabilities!\n","2. The chi-square test appropriate for large probabilities. \n","3. The chi-square test is not appropriate with sparse data (if numbers in the\n","2 by 2 tables are small ! Very low frquency bigrams might give a very high chi-squre values - misleading result!)\n","\n","The null hypothesis assumption is like in t-test\n","\n","for each bigram the following table is calculated:\n","\n","----------|     word1==a1           |   word1!=a1----------------------\n","----------|-------------------------|-----------------------------------  \n"," word1==a2| Count(\"a1 a1\")          | Count (\"x a2\")  (x!=a1)\n","----------|-------------------------|-----------------------------------\n","word2!=a2 |Count (\"a1 x\")  (x!=a2)  | Count (\"x1 x2\") (x1!=a1 & x2!=a2)\n","\n","\n"," $\\chi^2 =\\sum_{i,j}(Oij-Eij)^2/Eij$\n","\n"," Oij - value in the table above for row i column j\n","\n"," Eij - N*Count(a1)/N * Count(a2)/N\n","\n","Taking into account the mentioned in notice points, we should filter out results based on small frequencies ,after making an examination , we concluded that the bigrams with frequencies less than 20 , are less likely to form collocations ,thus we will ignore them in this test examination.\n","\n","**Likelihood ratios**\n","\n","Two Hypothesis used in Likelihood ratios :\n","\n","– Hypothesis 1 : formalization of independence , P(a2|a1)=p=P(a2|not a1)\n","\n","– Hypothesis 2 : formalization of dependence , P(a2|a1)=p1 != p2=P(a2|not a1)\n","\n","\n","Assuming binomial distribution the log likelihood raio is calculated as follows:\n","\n","log $\\lambda$ = log L(H1)/L(H2) =\n","log b(c12;c1,p)b(c1-c12;N-c1,p) / b(c12;c1,p1)b(c1-c12;N-c1,p2) =\n","log L(c21;c1,p)+log L(c2-c1;N-c1,p)-log L(c12;c1,p1)-log L(c1-c12;N-c1,p2)\n","\n","L(k;n,x)= $x^k$\\$(1-x)^n /$\\$(1-x)^k\\$\n","\n","c1- a1 frequency\n","\n","c2 - a2 frequency\n","\n","c12 - a12 bigram frequency\n","\n","N - total num. of words in corpus\n","\n","p=c2/N , p1=c12/c1 , p2=(c2-c12)/(N-c1)\n","\n","The higher the test value the more likely that a2 is the collocation of a1."]},{"cell_type":"markdown","metadata":{"id":"BDeWJWIcs-jS"},"source":["**T-test**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"yG6sEw6IHVpF","executionInfo":{"status":"ok","timestamp":1626946565631,"user_tz":-180,"elapsed":36276,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"b645fe66-442c-43f9-a578-d3d6403d939a"},"source":["bigramT_test = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.student_t)), columns=['bigram','t-score']).sort_values(by='t-score', ascending=False)\n","#filter out those collocations/co-occurances that not contain stop words,and are of the following structure:(Noun, Noun), (Adjective, Noun)\n","filteredT_bigrams = bigramT_test[bigramT_test.bigram.map(lambda x: clean_data.filter_matching(x))]\n","bigramT_test_freq=pd.merge(filteredT_bigrams, bigramFreq, on='bigram').sort_values(by='t-score', ascending=False)\n","#bigramT_test_freq_filtered=bigramT_test_freq[bigramT_test_freq['freq']>20].reset_index(drop=True)\n","bigramT_test_freq.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>t-score</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(front, desk)</td>\n","      <td>50.998854</td>\n","      <td>2616</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(great, location)</td>\n","      <td>27.315524</td>\n","      <td>795</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(friendly, staff)</td>\n","      <td>26.362455</td>\n","      <td>761</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(walk, distance)</td>\n","      <td>26.102098</td>\n","      <td>684</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(hot, tub)</td>\n","      <td>24.301816</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(continental, breakfast)</td>\n","      <td>22.689935</td>\n","      <td>521</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(free, breakfast)</td>\n","      <td>22.326432</td>\n","      <td>520</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(great, place)</td>\n","      <td>21.258349</td>\n","      <td>510</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(parking, lot)</td>\n","      <td>20.579494</td>\n","      <td>428</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(customer, service)</td>\n","      <td>20.305471</td>\n","      <td>415</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     bigram    t-score  freq\n","0             (front, desk)  50.998854  2616\n","1         (great, location)  27.315524   795\n","2         (friendly, staff)  26.362455   761\n","3          (walk, distance)  26.102098   684\n","4                (hot, tub)  24.301816   593\n","5  (continental, breakfast)  22.689935   521\n","6         (free, breakfast)  22.326432   520\n","7            (great, place)  21.258349   510\n","8            (parking, lot)  20.579494   428\n","9       (customer, service)  20.305471   415"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"dg-Cst2Yx4Vl"},"source":["What we can note is that the results pretty much resemble those ranked by just frequency."]},{"cell_type":"markdown","metadata":{"id":"R3VuA6RwxSpc"},"source":["**Chi-Square test**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"ieNG3YfNxSD6","executionInfo":{"status":"ok","timestamp":1626946602425,"user_tz":-180,"elapsed":36800,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"6a4b0592-2e26-45cc-ff37-ffb308d55b1f"},"source":["bigramChi_test = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq']).sort_values(by='chi-sq', ascending=False)\n","#filter out those collocations/co-occurances that not contain stop words,and are of the following structure:(Noun, Noun), (Adjective, Noun)\n","filteredChi_bigrams = bigramChi_test[bigramChi_test.bigram.map(lambda x: clean_data.filter_matching(x))]\n","bigramChi_test_freq=pd.merge(filteredChi_bigrams, bigramFreq, on='bigram').sort_values(by='chi-sq', ascending=False)\n","bigramChi_test_freq_filtered=bigramChi_test_freq[bigramChi_test_freq['freq']>20].reset_index(drop=True)\n","bigramChi_test_freq_filtered.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>chi-sq</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(wi, fi)</td>\n","      <td>1.450628e+06</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(cracker, barrel)</td>\n","      <td>1.180855e+06</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(howard, johnson)</td>\n","      <td>1.069493e+06</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(la, quinta)</td>\n","      <td>9.348547e+05</td>\n","      <td>130</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(front, desk)</td>\n","      <td>9.028557e+05</td>\n","      <td>2616</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(santa, barbara)</td>\n","      <td>7.898573e+05</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(santana, row)</td>\n","      <td>7.413207e+05</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(elk, springs)</td>\n","      <td>6.913309e+05</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(french, quarter)</td>\n","      <td>6.633053e+05</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(flat, screen)</td>\n","      <td>6.180737e+05</td>\n","      <td>115</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              bigram        chi-sq  freq\n","0           (wi, fi)  1.450628e+06   225\n","1  (cracker, barrel)  1.180855e+06    44\n","2  (howard, johnson)  1.069493e+06    38\n","3       (la, quinta)  9.348547e+05   130\n","4      (front, desk)  9.028557e+05  2616\n","5   (santa, barbara)  7.898573e+05    36\n","6     (santana, row)  7.413207e+05    51\n","7     (elk, springs)  6.913309e+05    58\n","8  (french, quarter)  6.633053e+05    98\n","9     (flat, screen)  6.180737e+05   115"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"vbEXncwH_CS0"},"source":["All the top 10 bigrams are actually collocations!"]},{"cell_type":"markdown","metadata":{"id":"XOLfiLhKJJn9"},"source":["**Likelihood test**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"KmGYOPzfJsjV","executionInfo":{"status":"ok","timestamp":1626946640205,"user_tz":-180,"elapsed":37786,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"406a99f7-02d0-4207-c9df-7fd6b52b3a2f"},"source":["bigramLikelihood_test = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.likelihood_ratio)), columns=['bigram','likelihood']).sort_values(by='likelihood', ascending=False)\n","#filter out those collocations/co-occurances that not contain stop words,and are of the following structure:(Noun, Noun), (Adjective, Noun)\n","filteredLikelihood_bigrams = bigramLikelihood_test[bigramLikelihood_test.bigram.map(lambda x: clean_data.filter_matching(x))]\n","bigramLikelihood_test_freq=pd.merge(filteredLikelihood_bigrams, bigramFreq, on='bigram').sort_values(by='likelihood', ascending=False)\n","#bigramLikelihood_test_freq_filtered=bigramLikelihood_test_freq[bigramLikelihood_test_freq['freq']>20].reset_index(drop=True)\n","bigramLikelihood_test_freq.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>likelihood</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(front, desk)</td>\n","      <td>31155.002334</td>\n","      <td>2616</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(walk, distance)</td>\n","      <td>8289.266979</td>\n","      <td>684</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(hot, tub)</td>\n","      <td>6791.858799</td>\n","      <td>593</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(continental, breakfast)</td>\n","      <td>5077.996503</td>\n","      <td>521</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(customer, service)</td>\n","      <td>4336.616941</td>\n","      <td>415</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(wi, fi)</td>\n","      <td>4291.368227</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(great, location)</td>\n","      <td>4191.052979</td>\n","      <td>795</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(parking, lot)</td>\n","      <td>3852.821968</td>\n","      <td>428</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(holiday, inn)</td>\n","      <td>3502.518990</td>\n","      <td>291</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(friendly, staff)</td>\n","      <td>3447.044517</td>\n","      <td>761</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     bigram    likelihood  freq\n","0             (front, desk)  31155.002334  2616\n","1          (walk, distance)   8289.266979   684\n","2                (hot, tub)   6791.858799   593\n","3  (continental, breakfast)   5077.996503   521\n","4       (customer, service)   4336.616941   415\n","5                  (wi, fi)   4291.368227   225\n","6         (great, location)   4191.052979   795\n","7            (parking, lot)   3852.821968   428\n","8            (holiday, inn)   3502.518990   291\n","9         (friendly, staff)   3447.044517   761"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"AVdLquTGK4-P"},"source":["Lets compare the results of the 3 performed tests!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":665},"id":"goHzpvEgKvmn","executionInfo":{"status":"ok","timestamp":1626946640207,"user_tz":-180,"elapsed":21,"user":{"displayName":"Polina Svidovsky","photoUrl":"","userId":"16302376773321913655"}},"outputId":"7d014299-1933-465f-c396-d117129396c9"},"source":["bigramsCompare=pd.DataFrame([bigramT_test_freq[['bigram']][:20].bigram.values,bigramChi_test_freq_filtered[['bigram']][:20].bigram.values,bigramLikelihood_test_freq[['bigram']][:20].bigram.values ]).T\n","bigramsCompare.columns=['T-test','Chi-square test','Likelihood ratio']\n","bigramsCompare"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>T-test</th>\n","      <th>Chi-square test</th>\n","      <th>Likelihood ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(front, desk)</td>\n","      <td>(wi, fi)</td>\n","      <td>(front, desk)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(great, location)</td>\n","      <td>(cracker, barrel)</td>\n","      <td>(walk, distance)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>(friendly, staff)</td>\n","      <td>(howard, johnson)</td>\n","      <td>(hot, tub)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(walk, distance)</td>\n","      <td>(la, quinta)</td>\n","      <td>(continental, breakfast)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(hot, tub)</td>\n","      <td>(front, desk)</td>\n","      <td>(customer, service)</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(continental, breakfast)</td>\n","      <td>(santa, barbara)</td>\n","      <td>(wi, fi)</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>(free, breakfast)</td>\n","      <td>(santana, row)</td>\n","      <td>(great, location)</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>(great, place)</td>\n","      <td>(elk, springs)</td>\n","      <td>(parking, lot)</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(parking, lot)</td>\n","      <td>(french, quarter)</td>\n","      <td>(holiday, inn)</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>(customer, service)</td>\n","      <td>(flat, screen)</td>\n","      <td>(friendly, staff)</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>(desk, staff)</td>\n","      <td>(red, roof)</td>\n","      <td>(air, conditioner)</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>(hotel, staff)</td>\n","      <td>(air, conditioner)</td>\n","      <td>(free, breakfast)</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>(comfortable, bed)</td>\n","      <td>(universal, studio)</td>\n","      <td>(next, door)</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>(nice, hotel)</td>\n","      <td>(walk, distance)</td>\n","      <td>(desk, clerk)</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>(clean, room)</td>\n","      <td>(credit, card)</td>\n","      <td>(easy, access)</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>(next, door)</td>\n","      <td>(air, conditioning)</td>\n","      <td>(hampton, inn)</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>(smoking, room)</td>\n","      <td>(hot, tub)</td>\n","      <td>(air, conditioning)</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>(pool, area)</td>\n","      <td>(san, francisco)</td>\n","      <td>(la, quinta)</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>(good, location)</td>\n","      <td>(top, notch)</td>\n","      <td>(smoking, room)</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>(desk, clerk)</td>\n","      <td>(ear, plug)</td>\n","      <td>(coffee, maker)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      T-test      Chi-square test          Likelihood ratio\n","0              (front, desk)             (wi, fi)             (front, desk)\n","1          (great, location)    (cracker, barrel)          (walk, distance)\n","2          (friendly, staff)    (howard, johnson)                (hot, tub)\n","3           (walk, distance)         (la, quinta)  (continental, breakfast)\n","4                 (hot, tub)        (front, desk)       (customer, service)\n","5   (continental, breakfast)     (santa, barbara)                  (wi, fi)\n","6          (free, breakfast)       (santana, row)         (great, location)\n","7             (great, place)       (elk, springs)            (parking, lot)\n","8             (parking, lot)    (french, quarter)            (holiday, inn)\n","9        (customer, service)       (flat, screen)         (friendly, staff)\n","10             (desk, staff)          (red, roof)        (air, conditioner)\n","11            (hotel, staff)   (air, conditioner)         (free, breakfast)\n","12        (comfortable, bed)  (universal, studio)              (next, door)\n","13             (nice, hotel)     (walk, distance)             (desk, clerk)\n","14             (clean, room)       (credit, card)            (easy, access)\n","15              (next, door)  (air, conditioning)            (hampton, inn)\n","16           (smoking, room)           (hot, tub)       (air, conditioning)\n","17              (pool, area)     (san, francisco)              (la, quinta)\n","18          (good, location)         (top, notch)           (smoking, room)\n","19             (desk, clerk)          (ear, plug)           (coffee, maker)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"uQ6bTbJ_Osbq"},"source":["**Conclusion**\n","\n","The superiority of the Chi-square test results and the Likelihood ratios results over the results of the t-test is very obvious.\n","The basic statistical assumption of the t-test limits the application of this test.\n","\n","The results demonstrated by both Chi-square test and the Likelihood test are quite similar , however the last definitely preferable since it doesn't have the limiting assumptions of the Chi-square test , and as a consequence it doesn't require any visual data examination and assumption as we did for low frequency items.\n"]}]}